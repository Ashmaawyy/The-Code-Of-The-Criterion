# The Code of The Criterion (Al-Furqan)
## Criterion Eval v5.0 — Veridical Substrate

### Overview
The Criterion is an **axiom-driven evaluation framework** designed to test reasoning systems against a **non-relative standard of truth**.

This project addresses a core problem in AI alignment and epistemology:

> There is no neutral or void space outside of frameworks.  
> All reasoning systems operate under assumptions.  
> Therefore, evaluation must occur against an explicit reference.

Criterion Eval v5.0 formalizes this insight.

---

### What This Is
- A **meta-evaluation framework** for reasoning systems
- A **deductive pipeline** (Scan → Mirror → Verdict)
- A **teleology-aware alignment benchmark**
- A **human-noise–resistant test** for AI reasoning drift

---

### What This Is Not
- Not a statistical model
- Not a probabilistic ethics engine
- Not a neutral relativist benchmark
- Not opinion-based analysis

---

## Core Principle
Truth must be **above** all human frameworks in order to evaluate them.

Criterion Eval does not assume neutrality.  
It assumes **explicit axioms** and tests all reasoning against them.

---

## Core Axioms (Self-Evident Necessities)
1. Design implies purpose.
2. Normality is defined by optimal system functioning.
3. Actions have compounded network consequences.

These axioms are treated as **logical necessities**, not cultural opinions.

---

## Evaluation Architecture

### 1. Deductive Pipeline
- **Scan**: Identify the system involved (economic, social, spiritual, etc.)
- **Mirror**: Compare it against axioms and the operational Manual
- **Verdict**: Deduce consequences, actors, and mechanisms

### 2. Survival Gates
- Source-Integrity
- Structural-Consistency
- Mediation-Zeroing
- Origin-Aware Recognition

---

## Project Structure

```
The-Code-Of-The-Criterion/
│
├── axioms/
│   └── core_axioms.json           # Core axioms definitions
│
├── config/
│   └── settings.yaml              # Configuration and settings
│
├── evaluation/
│   ├── gates.py                   # Evaluation gates logic
│   └── pipeline.py                # Main evaluation pipeline
│
├── logs/
│   └── sample_log.txt             # Sample log output
│
├── LICENSE                        # Project license
├── README.md                       # This file
└── The-Criterion-Prompt.md        # Framework specification
```

### Key Directories

| Directory | Purpose |
|-----------|---------|
| `axioms/` | Core axioms that form the logical foundation (JSON definitions) |
| `config/` | Configuration and settings (YAML format) |
| `evaluation/` | Core evaluation logic - gates and pipeline implementation (Python) |
| `logs/` | Execution records and sample output |

---

## Output
- Plain-text logs
- Deterministic reasoning traces
- No forced JSON
- Suitable for audits, research review, and alignment testing

---

## Why This Matters for AI Research
- Prevents hidden framework drift
- Exposes implicit secular assumptions
- Forces explicit reasoning commitments
- Enables truth-centered alignment testing

---

## License
MIT
